<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title type="html">Running Custom Tasks in jBPM With Work Item Handlers</title><link rel="alternate" href="https://blog.kie.org/2022/08/running-custom-tasks-in-jbpm-with-work-item-handlers.html" /><author><name>Helber Belmiro</name></author><id>https://blog.kie.org/2022/08/running-custom-tasks-in-jbpm-with-work-item-handlers.html</id><updated>2022-08-11T12:04:03Z</updated><content type="html">RUNNING CUSTOM TASKS IN JBPM WITH WORK ITEM HANDLERS INTRODUCTION You can use a WorkItemHandler to run custom tasks during the execution of a process in jBPM. In this article, you will run through the steps to create a custom task and use it in a process. &gt; IMPORTANT: This tutorial uses version 7.72.0.Final of jBPM. The application you’re going to create is a process that concatenates first and last names, and prints the result to the console. The concatenation is going to be processed in a custom task. So, start by creating the WorkItemHandler. &gt; NOTE: If you don’t want to create the project, you can clone it from . CREATING THE WORKITEMHANDLER 1. Run the following command to create a work item handler project: mvn archetype:generate \ -DarchetypeGroupId=org.jbpm \ -DarchetypeArtifactId=jbpm-workitems-archetype \ -DarchetypeVersion=7.72.0.Final \ -DgroupId=org.acme \ -DartifactId=myconcatworkitem \ -Dversion=1.0.0-SNAPSHOT \ -DclassPrefix=MyConcat 2. Replace the content of src/main/java/org/acme/MyConcatWorkItemHandler.java file with the following: package org.acme; import org.jbpm.process.workitem.core.AbstractLogOrThrowWorkItemHandler; import org.jbpm.process.workitem.core.util.RequiredParameterValidator; import org.jbpm.process.workitem.core.util.Wid; import org.jbpm.process.workitem.core.util.WidMavenDepends; import org.jbpm.process.workitem.core.util.WidParameter; import org.jbpm.process.workitem.core.util.WidResult; import org.jbpm.process.workitem.core.util.service.WidAction; import org.jbpm.process.workitem.core.util.service.WidAuth; import org.jbpm.process.workitem.core.util.service.WidService; import org.kie.api.runtime.process.WorkItem; import org.kie.api.runtime.process.WorkItemManager; import java.util.HashMap; import java.util.Map; @Wid(widfile = "MyConcatDefinitions.wid", name = "MyConcatDefinitions", displayName = "MyConcatDefinitions", defaultHandler = "mvel: new org.acme.MyConcatWorkItemHandler()", documentation = "myconcatworkitem/index.html", category = "myconcatworkitem", icon = "MyConcatDefinitions.png", parameters = { @WidParameter(name = "FirstName"), @WidParameter(name = "LastName") }, results = { @WidResult(name = "FullName") }, mavenDepends = { @WidMavenDepends(group = "org.acme", artifact = "myconcatworkitem", version = "1.0.0-SNAPSHOT") }, serviceInfo = @WidService(category = "myconcatworkitem", description = "${description}", keywords = "", action = @WidAction(title = "Sample Title"), authinfo = @WidAuth(required = true, params = {"FirstName", "LastName"}, paramsdescription = {"First name", "Last name"}, referencesite = "referenceSiteURL") ) ) public class MyConcatWorkItemHandler extends AbstractLogOrThrowWorkItemHandler { public void executeWorkItem(WorkItem workItem, WorkItemManager manager) { try { RequiredParameterValidator.validate(this.getClass(), workItem); String firstName = (String) workItem.getParameter("FirstName"); // Gets the "FirstName" parameter String lastName = (String) workItem.getParameter("LastName"); // Gets the "LastName" parameter String fullName = firstName + " " + lastName; // Concatenates the "firstName" and "lastName" Map results = new HashMap(); results.put("FullName", fullName); // Adds "fullName" to the "results" object manager.completeWorkItem(workItem.getId(), results); } catch (Throwable cause) { handleException(cause); } } @Override public void abortWorkItem(WorkItem workItem, WorkItemManager manager) { } } 3. Update the src/test/java/org/acme/MyConcatWorkItemHandlerTest.java test file with the following: package org.acme; import org.drools.core.process.instance.impl.WorkItemImpl; import org.jbpm.process.workitem.core.TestWorkItemManager; import org.jbpm.test.AbstractBaseTest; import org.junit.Test; import static org.junit.Assert.assertEquals; import static org.junit.Assert.assertNotNull; import static org.junit.Assert.assertTrue; public class MyConcatWorkItemHandlerTest extends AbstractBaseTest { @Test public void testHandler() { WorkItemImpl workItem = new WorkItemImpl(); workItem.setParameter("FirstName", "John"); workItem.setParameter("LastName", "Doe"); TestWorkItemManager manager = new TestWorkItemManager(); MyConcatWorkItemHandler handler = new MyConcatWorkItemHandler(); handler.setLogThrownException(true); handler.executeWorkItem(workItem, manager); assertNotNull(manager.getResults()); assertEquals(1, manager.getResults().size()); assertEquals("John Doe", manager.getResults().get(0L).get("FullName")); assertTrue(manager.getResults().containsKey(workItem.getId())); } } 4. Package and install the work item handler project into your Maven local repository. From the myconcatworkitem directory, run: mvn clean install You should see the generated myconcatworkitem-1.0.0-SNAPSHOT.jar file in the target directory. ADDING THE WORK ITEM HANDLER TO BUSINESS CENTRAL AS A CUSTOM TASK 1. Open Business Central 2. Click the gear icon in the upper-right corner 3. Click "Custom Tasks Administration" 4. Click the "Add Custom Task" button 5. Upload the myconcatworkitem-1.0.0-SNAPSHOT.jar file. After the upload, the Custom Task should appear in the list of Custom Tasks in the same window as the "Add Custom Task" button 6. Locate the Custom Task (MyConcatDefinitions) in the list and activate it INSTALLING THE CUSTOM TASK IN YOUR PROJECT 1. Open your project in Business Central and click "Settings" 2. Click "Custom Tasks" on the left corner 3. Click the "Install" button of the Custom Task (MyConcatDefinitions) 4. Click the "Save" button 5. On the left side of the screen, click "Dependencies" 6. Click "Add from Repository" and then search for the "myconcatworkitem" artifact and select it 7. Click the "Save" button and confirm the dialog USING THE CUSTOM TASK 1. Create a new Business Process 2. Add three process variables to the process. In "Properties", expand "Process Data" and add the following String variables: * firstName * lastName * fullName 3. Add a new Start Event 4. Add a new End Event 5. Click "Custom Tasks" (gear button on the left side of the screen), select "MyConcatDefinitions" and add it to the process 6. Select the node you just added and in Properties, expand "Data Assignments" and click the edit button 7. Bind the process variables to the Custom Task parameters and click OK 8. Add a Script Task to the process 9. Select the node you just added and in Properties, expand "Implementation/Execution" and add the following script: System.out.println(fullName); 10. Connect all the nodes in the process Start - MyConcatDefinitions - Task - End 11. Save and deploy the process When you start a new process instance, you’ll be asked to enter the first and last names. After submitting, you will see the concatenated fullName in the console. CONCLUSION In this tutorial, you’ve learned how to create and use a custom work item handler in jBPM by creating a process that concatenates the first and last names received as parameters. The post appeared first on .</content><dc:creator>Helber Belmiro</dc:creator></entry><entry><title>Connect to services on Kubernetes easily with kube-service-bindings</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/08/11/connect-services-kubernetes-easily-kube-service-bindings" /><author><name>Costas Papastathis, Michael Dawson</name></author><id>321fb836-2526-4793-b7e5-aab63bfa6520</id><updated>2022-08-11T07:00:00Z</updated><published>2022-08-11T07:00:00Z</published><summary type="html">&lt;p&gt;One of the projects the &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js&lt;/a&gt; team at Red Hat has been focusing on over the past year is the development of &lt;a href="https://www.npmjs.com/package/kube-service-bindings"&gt;kube-service-bindings&lt;/a&gt; for &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;. We've found that combining the &lt;a href="https://operatorhub.io/operator/service-binding-operator"&gt;Service Binding Operator&lt;/a&gt; and kube-service-bindings is a convenient and consistent way of sharing credentials for services, letting you easily secure your deployments.&lt;/p&gt; &lt;p&gt;This article is the first of a three-part series. Our goals in the series are to:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Introduce Kubernetes service bindings and the Service Binding Operator.&lt;/li&gt; &lt;li&gt;Explain how the kube-service-bindings NPM package supports service bindings for Node.js applications.&lt;/li&gt; &lt;li&gt;Cover the clients we've added support for in kube-service-bindings.&lt;/li&gt; &lt;li&gt;Show an end-to-end deployment of a Node.js application communicating with a database in a Kubernetes setting.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;By the end of the series, you should have a better understanding of how service bindings and kube-service-bindings work. This first article explains the tools we're using and their benefits for Node.js programmers using Kubernetes.&lt;/p&gt; &lt;h2&gt;What are service bindings and the Service Binding Operator?&lt;/h2&gt; &lt;p&gt;In our &lt;a href="https://docs.openshift.com/container-platform/4.9/applications/connecting_applications_to_services/understanding-service-binding-operator.html#service-binding-terminology"&gt;service binding terminology for Kubernetes&lt;/a&gt;, a service binding provides information about a service to a process that needs to bind to that service. In subsequent parts of this series, for instance, you will use a service binding to provide the credentials of a &lt;a href="https://www.mongodb.com"&gt;MongoDB&lt;/a&gt; database when your Node.js application connects to it. The database is called a &lt;em&gt;backing service&lt;/em&gt;, while the application is called the &lt;em&gt;workload&lt;/em&gt;. The data passed between them is called &lt;em&gt;binding data&lt;/em&gt;.&lt;/p&gt; &lt;p&gt;Protocols and rules for sharing information are laid out in the &lt;a href="https://github.com/servicebinding/spec#service-binding-specification-for-kubernetes"&gt;Service Binding Specification for Kubernetes&lt;/a&gt;. The Service Binding Operator (SBO) establishes a connection to share the credentials between the workload and backing service. The SBO is &lt;a href="https://github.com/redhat-developer/service-binding-operator"&gt;implemented by Red Hat&lt;/a&gt; and is available in the &lt;a href="https://operatorhub.io/"&gt;OpenShift Operator Hub&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The Service Binding Operator has two significant benefits compared to other methods of sharing secrets. The first is security: The SBO requires less exposure of credentials or secrets throughout the &lt;a href="https://developers.redhat.com/topics/ci-cd"&gt;CI/CD&lt;/a&gt; process. The second benefit is convenience: Rarely is development as easy as dragging a line in a graphical user interface (UI) in the &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt; console.&lt;/p&gt; &lt;p&gt;You can find more information on how the Service Binding Operator works in the article &lt;a href="https://developers.redhat.com/articles/2021/10/27/announcing-service-binding-operator-10-ga"&gt;Announcing Service Binding Operator 1.0 GA&lt;/a&gt;. The article &lt;a href="https://developers.redhat.com/articles/2022/03/28/simplify-secure-connections-postgresql-databases-nodejs"&gt;Simplify secure connections to PostgreSQL databases with Node.js&lt;/a&gt; provides information about using the SBO to share credentials among backing services and compares the technique to others, using as an example the PostgreSQL client supported by kube-service-bindings.&lt;/p&gt; &lt;p&gt;In the background, the SBO:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Passes a variable named &lt;code&gt;SERVICE_BINDING_ROOT&lt;/code&gt; to the application environment to direct it to the credentials.&lt;/li&gt; &lt;li&gt;Projects the binding data into the application container, under the directory &lt;code&gt;/$SERVICE_BINDING_ROOT/&lt;application-name&gt;&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;What is kube-service-bindings and how does it work?&lt;/h2&gt; &lt;p&gt;kube-service-bindings finds, parses, and transforms data such as credentials into a consumable format appropriate for each client, such as a database. kube-service-bindings checks the &lt;code&gt;SERVICE_BINDING_ROOT&lt;/code&gt; environment variable to find which directory in the application instance has the binding data. The presence of the &lt;code&gt;SERVICE_BINDING_ROOT&lt;/code&gt; variable indicates that binding data is available. If the environment variable or binding data are not available, kube-service-bindings throws an error, which can easily be discovered through a try/catch block.&lt;/p&gt; &lt;p&gt;Besides parsing the data, kube-service-bindings knows exactly what it takes to provide the right configuration for each client, another advantage to using the package. Our goal in developing kube-service-bindings is to support the most common clients. We started by supporting backing services listed in the General Availability (GA) release for the Red Hat Service Binding Operator, as outlined in the section &lt;a href="https://developers.redhat.com/articles/2021/10/27/announcing-service-binding-operator-10-ga#extracting_the_binding_data_from_backing_services"&gt;Extracting the binding data from backing services&lt;/a&gt; of the previously mentioned article.&lt;/p&gt; &lt;p&gt;Version 1.0 of kube-service-bindings has made a good start in its support for clients. We would like to prioritize our work based on the needs of the community, so feel free to open a request in &lt;a href="https://github.com/nodeshift/kube-service-bindings/issues"&gt;the kube-service-bindings repository&lt;/a&gt; for the next client you would like to see supported.&lt;/p&gt; &lt;p&gt;Table 1 shows the currently supported clients. To connect to a client, the Node.js program issues a &lt;code&gt;getBinding&lt;/code&gt; call, passing the type (column 1) as the first argument and the client (column 2) as the second.&lt;/p&gt; &lt;div&gt; &lt;table cellspacing="0" width="NaN"&gt; &lt;caption&gt;Table 1: Clients currently supported by kube-service-bindings.&lt;/caption&gt; &lt;tbody&gt; &lt;tr&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt; &lt;p&gt;Type&lt;/p&gt; &lt;/th&gt; &lt;th&gt; &lt;p&gt;Client&lt;/p&gt; &lt;/th&gt; &lt;th&gt; &lt;p&gt;Date Added&lt;/p&gt; &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td width="NaN"&gt; &lt;p&gt;AMQP&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;&lt;a href="https://www.npmjs.com/package/rhea"&gt;rhea&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;March 2022&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td width="NaN"&gt; &lt;p&gt;Kafka&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;&lt;a href="https://www.npmjs.com/package/node-rdkafka"&gt;node-rdkafka&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;April 2021&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td width="NaN"&gt; &lt;p&gt;Kafka&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;&lt;a href="https://www.npmjs.com/package/kafkajs"&gt;kafkajs&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;April 2021&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td width="NaN"&gt; &lt;p&gt;MongoDB&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;&lt;a href="https://www.npmjs.com/package/mongodb"&gt;MongoDB&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;February 2022&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td width="NaN"&gt; &lt;p&gt;MongoDB&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;&lt;a href="https://www.npmjs.com/package/mongoose"&gt;mongoose&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;June 2022&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td width="NaN"&gt; &lt;p&gt;MySQL&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;&lt;a href="https://www.npmjs.com/package/mysql"&gt;MySQL&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;May 2022&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td width="NaN"&gt; &lt;p&gt;MySQL&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;&lt;a href="https://www.npmjs.com/package/mysql2"&gt;MySQL 2&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;May 2022&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td width="NaN"&gt; &lt;p&gt;MySQL&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;&lt;a href="https://www.npmjs.com/package/odbc"&gt;odbc&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;May 2022&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td width="NaN"&gt; &lt;p&gt;PostgreSQL&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;&lt;a href="https://www.npmjs.com/package/odbc"&gt;odbc&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;June 2022&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td width="NaN"&gt; &lt;p&gt;PostgreSQL&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;&lt;a href="https://www.npmjs.com/package/pg"&gt;postgres&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;December 2021&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td width="NaN"&gt; &lt;p&gt;Redis&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;&lt;a href="https://www.npmjs.com/package/redis"&gt;redis&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;January 2022&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td width="NaN"&gt; &lt;p&gt;Redis&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;&lt;a href="https://www.npmjs.com/package/ioredis"&gt;ioredis&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;January 2022&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/div&gt; &lt;h2&gt;Simplifying access to services on Kubernetes&lt;/h2&gt; &lt;p&gt;This article has explained the roles of the Service Binding Operator and kube-service-bindings in making it easy to connect to backing services such as databases. Subsequent articles in this series will go through an example that connects a Node.js application to a database using these tools.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/08/11/connect-services-kubernetes-easily-kube-service-bindings" title="Connect to services on Kubernetes easily with kube-service-bindings"&gt;Connect to services on Kubernetes easily with kube-service-bindings&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Costas Papastathis, Michael Dawson</dc:creator><dc:date>2022-08-11T07:00:00Z</dc:date></entry><entry><title type="html">This Week in JBoss - 11 August 2022</title><link rel="alternate" href="https://www.jboss.org/posts/weekly-2022-08-11.html" /><category term="quarkus" /><category term="kubernetes" /><category term="java" /><category term="jakarta" /><category term="infinispan" /><category term="wildfly" /><category term="cloud-native" /><category term="openshift" /><category term="kogito" /><category term="drools" /><category term="keycloak" /><author><name>Don Naro</name><uri>https://www.jboss.org/people/don-naro</uri><email>do-not-reply@jboss.com</email></author><id>https://www.jboss.org/posts/weekly-2022-08-11.html</id><updated>2022-08-11T00:00:00Z</updated><content type="html">&lt;article class="" data-tags="quarkus, kubernetes, java, jakarta, infinispan, wildfly, cloud-native, openshift, kogito, drools, keycloak"&gt; &lt;h1&gt;This Week in JBoss - 11 August 2022&lt;/h1&gt; &lt;p class="preamble"&gt;&lt;/p&gt;&lt;p&gt;Hi everyone! It’s great to be back and bringing you another edition of the JBoss Editorial. As always there’s a lot of exciting news and updates from JBoss communities so let’s dive in.&lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;div class="sect1"&gt; &lt;h2 id="_release_roundup"&gt;Release roundup&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist square"&gt; &lt;ul class="square"&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://infinispan.org/blog/2022/08/09/infinispan-14"&gt;Infinispan 14.0.0.CR1&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.keycloak.org/2022/07/keycloak-1901-released.html"&gt;Keycloak 19.0.1&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://vertx.io/blog/eclipse-vert-x-4-3-3/"&gt;Eclipse Vert.x 4.3.3&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://resteasy.dev/2022/08/02/resteasy-6.1.0-release/"&gt;RESTEasy 6.1.0.Final&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/quarkus-2-11-2-final-released/"&gt;Quarkus 2.11.2.Final&lt;/a&gt; (&lt;code&gt;CVE-2022-2466&lt;/code&gt; is still ongoing)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.wildfly.org/news/2022/08/05/WildFly27-Alpha4-Released/"&gt;WildFly 27 Alpha4&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://blog.kie.org/2022/08/kogito-1-25-0-released.html"&gt;Kogito 1.25.0&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_wildfly_maven_plugin_to_create_container_images"&gt;WildFly Maven plugin to create container images&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://www.wildfly.org/news/2022/08/04/wildfly-maven-docker/"&gt;Use the wildfly-maven-plugin to create a Docker image of your application&lt;/a&gt;, by By Jeff Mesnil&lt;/p&gt; &lt;p&gt;Jeff explains how to use the &lt;code&gt;wildlfy-maven-plugin&lt;/code&gt; and the new WildFly runtime image to build container images. The WildFly Maven plugin, currently in beta with Final planned for WildFly 27, offers a new, and very compelling, architecture to control the full runtime from the application &lt;code&gt;pom.xml&lt;/code&gt;. Developers control the full customization of WildFly using feature packs, packaging scripts, and other artifacts. This approach ensures that the runtime fits the user’s application. Creating a container image is simply a matter of putting it in a runtime image that contains OpenJDK.&lt;/p&gt; &lt;p&gt;The WildFly team are starting an open conversation to bring additional synergies between the Docker and S2I images for WildFly that could benefit the whole community. The team are aiming to bring new capabilities, additional architectures (in particular &lt;code&gt;linux/arm64&lt;/code&gt;), and newer versions of the JDK to all WildFly images. Be sure to check out Jeff’s post and find out how you can get involved!&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_jakarta_bean_validation"&gt;Jakarta Bean Validation&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="http://www.mastertheboss.com/java-ee/validation/test/"&gt;Getting started with Jakarta Bean Validation&lt;/a&gt;, by Francesco Marchioni&lt;/p&gt; &lt;p&gt;Francesco takes a look at the Jakarta Bean Validation specification which allows you to express constraints on your model and create custom ones in an extensible way. His detailed post shows you how to write a constraint once and use it in any application layer. Given that Bean validation is layer agnostic, meaning that you can use the same constraint from the presentation to the business model layer.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_kogito_rules_drools_with_java_inheritance"&gt;Kogito Rules (Drools) with Java Inheritance&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://blog.kie.org/2022/08/kogito-rules-drools-with-java-inheritance.html"&gt;Kogito Rules (Drools) with Java Inheritance&lt;/a&gt;, by Jeff Taylor&lt;/p&gt; &lt;p&gt;In this article, Jeff explains how Kogito rules services can reason over application domain model facts that are represented using plain old Java objects, or POJOs, that use standard Java inheritance. DRL rules files can use POJOs as well as client applications that call the Kogito rules services.&lt;/p&gt; &lt;p&gt;Jeff explores two approaches for sharing Java subclasses between a Kogito rules service and a client application. The first approach isolates objects from each subclass into a JSON array while the second approach uses Jackson inheritance annotations to embed objects from each subclass for REST API calls that serialize and deserialize POJOs to and from JSOn.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_welcome_václav_muzikář"&gt;Welcome Václav Muzikář!&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://www.keycloak.org/2022/08/vaclav"&gt;New Keycloak maintainer: Václav Muzikář&lt;/a&gt;, by Bruno Oliveira&lt;/p&gt; &lt;p&gt;The Keycloak team has a new community maintainer! Hearty welcome to Václav Muzikář.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_youtube_videos"&gt;YouTube videos&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;From unmissable demos to brilliant chat about the latest Java trends, the JBoss community has some great video content for you:&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/Urj1X60H6YY"&gt;Quarkus Insights #98: Using Minecraft as an Observability client&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/nH-27gOp0h4"&gt;Quarkus Insights #97: Qute with Quarkus&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/kdasoBPOWUQ"&gt;Quarkus Insights #96: Quarkus Q&amp;#38;A&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/9DMAkrM_gOA"&gt;MLOps with Flyte with Samhita Alla&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_see_you_next_time"&gt;See you next time&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;em&gt;Hope you enjoyed this edition. Please join us again in two weeks for our JBoss editorial!&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="author"&gt; &lt;pfe-avatar pfe-shape="circle" pfe-pattern="squares" pfe-src="/img/people/don-naro.png"&gt;&lt;/pfe-avatar&gt; &lt;span&gt;Don Naro&lt;/span&gt; &lt;/div&gt;&lt;/article&gt;</content><dc:creator>Don Naro</dc:creator></entry><entry><title type="html">Kogito Rules (Drools) with Java Inheritance</title><link rel="alternate" href="https://blog.kie.org/2022/08/kogito-rules-drools-with-java-inheritance.html" /><author><name>Jeff Taylor</name></author><id>https://blog.kie.org/2022/08/kogito-rules-drools-with-java-inheritance.html</id><updated>2022-08-10T11:36:00Z</updated><content type="html">COMPARISON OF A JSON ARRAY BASED APPROACH VS JACKSON INHERITANCE ANNOTATIONS -------------------------------------------------------------------------------- INTRODUCTION: “Kogito is a next generation business automation toolkit that originates from well known Open Source projects Drools (for business rules) and jBPM (for business processes). Kogito aims at providing another approach to business automation where the main message is to expose your business knowledge (processes, rules and decisions) in a domain specific way.” (4) Kogito rules services can reason over application domain model facts that are represented using “plain old Java objects” (POJO’s). The POJO’s can be used in DRL rules files and additionally the POJO’s may be used by the client applications that call the Kogito rules services. The communication layer between the rules service and the client application often uses RestAPI calls where the POJO’s are serialized and deserialize, to and from JSON. The POJO’s may use standard Java inheritance. This paper explores two approaches for sharing Java subclasses between the rules service and the client application. The first approach uses JSON arrays to isolate the objects from each subclass into its own array. The second approach uses Jackson inheritance annotations so that the subclass of every object will be embedded during the RestAPI request and response. Examples of the two approaches are available here: * * BACKGROUND: “For any rule base application, a fact model is needed to drive the rules. The fact model typically overlaps with the applications domain model, but in general it will be decoupled from it (as it makes the rules easier to manage over time). There are no technical limitations on using your domain model as your fact model, however this introduces tighter coupling between your business domain (domain model) and your knowledge domain (fact model). Consequentially if your domain model were to change you would need to, at the very least, revisit your rule definitions.” (8) “Red Hat Decision Manager supports several assets that you can use to define business decisions for your decision service. Each decision-authoring asset has different advantages, and you might prefer to use one or a combination of multiple assets depending on your goals and needs. DRL (Drools Rule Language) rules are business rules that you define directly in .drl text files.” (9) EXAMPLE SHARED FACT INHERITANCE MODEL: Class diagram for the common fact model Goal: Create DRL rules to identify the overloaded cars and trucks. First Approach: Each payload includes a JSON array of each subclass: First Approach superclass: package com.example.vehicle.datamodel; @lombok.Getter @lombok.Setter public class Vehicle { private String color; private Integer vehicleId; private Boolean overloaded = false; } First Approach example JSON payload Five vehicles: One generic , two cars and two trucks. Notice that although every instance shares the same superclass, instances of every subclass are isolated into their own JSON array. { "vehicleInstances": [ { "color": "red", "vehicleId": 1 } ], "carInstances": [ { "color": "bright green", "vehicleId": 2, "currentPassengers": 5, "maxPassengers": 4 }, { "color": "lime green", "vehicleId": 3, "currentPassengers": 2, "maxPassengers": 5 } ], "truckInstances": [ { "color": "medium blue", "vehicleId": 4, "currentCargoWeight": 5000, "maxCargoWeight": 4000 }, { "color": "navy blue", "vehicleId": 5, "currentCargoWeight": 2000, "maxCargoWeight": 5000 } ] } First Approach: Rule Unit Data for JSON array of each subclass Set up the rule unit data to receive the arrays of subclasses: public class VehicleUnitData implements RuleUnitData { public DataStore&lt;Vehicle&gt; vehicleInstances = DataSource.createStore(); public DataStore&lt;Car&gt; carInstances = DataSource.createStore(); public DataStore&lt;Truck&gt; truckInstances = DataSource.createStore(); } First Approach: Rules to work with list of subclasses rule "Car Rule using list of subclasses" when $c : /carInstances[ currentPassengers &gt; maxPassengers ] then modify($c){setOverloaded(true)}; end rule "Truck Rule using list of subclasses" when $t : /truckInstances[currentCargoWeight &gt; maxCargoWeight] then modify($t){setOverloaded(true)}; end query "GetOverloadedCars" $c: /carInstances[overloaded] end query "GetOverloadedTrucks" $t: /truckInstances[overloaded] end query "GetOverloadedVehicles" $t: /vehicleInstances[overloaded] end First Approach usage: ## Call the Car RestAPI endpoint $ cat VehicleAppList/src/main/resources/payload.json | curl -s -d@- -H "Content-type: application/json" http:/localhost:8080/get-overloaded-cars | jq [ { "color": "bright green", "vehicleId": 2, "overloaded": true, "currentPassengers": 5, "maxPassengers": 4 } ] ## Call the Truck RestAPI endpoint $ cat VehicleAppList/src/main/resources/payload.json | curl -s -d@- -H "Content-type: application/json" http:/localhost:8080/get-overloaded-trucks | jq [ { "color": "medium blue", "vehicleId": 4, "overloaded": true, "currentCargoWeight": 5000, "maxCargoWeight": 4000 } ] -------------------------------------------------------------------------------- Second Approach: Using Jackson Inheritance Annotations so that each payload includes an attribute to self identify it’s own subclass: Second Approach superclass: package com.example.vehicle.datamodel; import com.fasterxml.jackson.annotation.JsonSubTypes; import com.fasterxml.jackson.annotation.JsonSubTypes.Type; import com.fasterxml.jackson.annotation.JsonTypeInfo; @lombok.Getter @lombok.Setter @JsonTypeInfo( use = JsonTypeInfo.Id.NAME, include = JsonTypeInfo.As.PROPERTY, property = "vehicleType", visible = true) @JsonSubTypes({ @Type(value = Car.class, name = "Car"), @Type(value = Truck.class, name = "Truck") }) public class Vehicle { private String color; private Integer vehicleId; private Boolean overloaded = false; private String vehicleType; } Second Approach example JSON payload Five vehicles: One generic , two cars and two trucks. Notice that every instance identifies it’s own subclass. { "vehicleInstances": [ { "vehicleType": "Vehicle", "color": "red", "vehicleId": 1 }, { "vehicleType": "Car", "color": "bright green", "vehicleId": 2, "currentPassengers": 5, "maxPassengers": 4 }, { "vehicleType": "Car", "color": "lime green", "vehicleId": 3, "currentPassengers": 2, "maxPassengers": 5 }, { "vehicleType": "Truck", "color": "medium blue", "vehicleId": 4, "currentCargoWeight": 5000, "maxCargoWeight": 4000 }, { "vehicleType": "Truck", "color": "navy blue", "vehicleId": 5, "currentCargoWeight": 2000, "maxCargoWeight": 5000 } ] } Second Approach: Rule Unit Data for JSON array of the superclass package com.example.vehicle.rules; import com.example.vehicle.datamodel.Vehicle; import org.kie.kogito.rules.DataSource; import org.kie.kogito.rules.DataStore; import org.kie.kogito.rules.RuleUnitData; @lombok.Getter @lombok.Setter public class VehicleUnitData implements RuleUnitData { public DataStore&lt;Vehicle&gt; vehicleInstances = DataSource.createStore(); } Second Approach: Rules to work with the subclasses package com.example.vehicle.rules; unit VehicleUnitData; import com.example.vehicle.datamodel.Car; import com.example.vehicle.datamodel.Truck; rule "Car Rule" when $v : /vehicleInstances#Car[ currentPassengers &gt; maxPassengers ] then modify($v){setOverloaded(true)}; end rule "Truck Rule" when $v : /vehicleInstances#Truck[ currentCargoWeight &gt; maxCargoWeight ] then modify($v){setOverloaded(true)}; end query "GetOverloadedVehicles" $v: /vehicleInstances[overloaded] end Second Approach usage: $ cat VehicleAppPoly/src/main/resources/payload.json | curl -s -d@- -H "Content-type: application/json" http:/localhost:8080/get-overloaded-vehicles | jq [ { "vehicleType": "Car", "color": "bright green", "vehicleId": 2, "overloaded": true, "currentPassengers": 5, "maxPassengers": 4 }, { "vehicleType": "Truck", "color": "medium blue", "vehicleId": 4, "overloaded": true, "currentCargoWeight": 5000, "maxCargoWeight": 4000 } ] Conclusion: Jackson inheritance annotations can be used to track the type of Java subclasses of that will be used as facts for the Kogito rules engine. APPENDIX: NOTES ON THE CREATION OF THE MAVEN MODULES: CONSTRUCT THE PARENT: a. Create the parent maven module $ quarkus create app --no-code com.example.vehicle:VehicleApp:2.0.0-SNAPSHOT b. Change the packaging to pom type and add lombok. Edit VehicleApp/pom.xml ... &lt;packaging&gt;pom&lt;/packaging&gt; &lt;properties&gt; ... &lt;lombok.version&gt;1.18.24&lt;/lombok.version&gt; &lt;/properties&gt; ... &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;${lombok.version}&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 2. CONSTRUCT THE DATA MODEL a. Create the datamodel maven project $ cd VehicleApp/ $ quarkus ext add quarkus-resteasy quarkus-resteasy-jackson $ mvn archetype:generate \ -DarchetypeArtifactId=maven-archetype-quickstart \ -DarchetypeVersion=1.4 \ -DgroupId=com.example.vehicle \ -DartifactId=datamodel \ -Dversion=2.0.0-SNAPSHOT b. Directory: $ mkdir -p datamodel/src/main/java/com/example/vehicle/datamodel c. Vehicle superclass: package com.example.vehicle.datamodel; @lombok.Getter @lombok.Setter public class Vehicle { private String color; private Integer vehicleId; private Boolean overloaded = false; } d. Car subclass package com.example.vehicle.datamodel; @lombok.Getter @lombok.Setter public class Car extends Vehicle { private Integer currentPassengers; private Integer maxPassengers; } e. Truck subclass package com.example.vehicle.datamodel; @lombok.Getter @lombok.Setter public class Truck extends Vehicle { private Integer currentCargoWeight; private Integer maxCargoWeight; } 3. CONSTRUCT THE VEHICLE-DECISION-SERVICE MAVEN PROJECT a. Create the Kogito Rules project mvn io.quarkus.platform:quarkus-maven-plugin:2.11.1.Final:create \ -DprojectGroupId=com.example.vehicle \ -DprojectArtifactId=vehicle-decision-service \ -Dversion=2.0.0-SNAPSHOT \ -Dextensions="kogito-quarkus-rules,quarkus-resteasy,quarkus-resteasy-jackson,quarkus-smallrye-openapi" b. Add directories for the DRL files and the RuleUnit mkdir vehicle-decision-service/src/main/resources/vehicle mkdir vehicle-decision-service/src/main/java/vehicle/ REFERENCES: 1. “Design Patterns in Production Systems” () 2. “Using DRL rules in Kogito services” () 3. “Drools Documentation” () 4. “Using Kogito to add rule engine capabilities to an application” () 5. “Writing Json Rest Services” () 6. “Inheritance with Jackson” () 7. “Automating rule-based services with Java and Kogito” () 8. “The Fact Model” () 9. “Decision-authoring assets in Red Hat Decision Manager” () The post appeared first on .</content><dc:creator>Jeff Taylor</dc:creator></entry><entry><title>How to configure Podman 4.0 for IPv6</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/08/10/how-conifgure-podman-40-ipv6" /><author><name>Ranjith Rajaram</name></author><id>190aad79-396f-4282-abbd-1cdc361872fa</id><updated>2022-08-10T07:00:00Z</updated><published>2022-08-10T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://podman.io/"&gt;Podman&lt;/a&gt; is a major &lt;a href="https://developers.redhat.com/topics/containers"&gt;container&lt;/a&gt; platform, &lt;a href="https://developers.redhat.com/articles/2022/05/02/podman-basics-resources-beginners-and-experts"&gt;used by many developers&lt;/a&gt; in place of Docker. &lt;a href="https://podman.io/releases/2022/02/22/podman-release-v4.0.0.html"&gt;Podman v4.0&lt;/a&gt; has extensive new support for the IPv6 address format. IPv6 networks with Network Address Translation (NAT) and port forwarding are now fully tested and supported in this latest version of the platform. You can also assign static IPv6 addresses to containers in these networks.&lt;/p&gt; &lt;p&gt;Podman v4.0 is supported in versions 8.6 and 9 of &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt;. This article shows you how to enable the new IPv6 support.&lt;/p&gt; &lt;h2&gt;Changes to Podman&lt;/h2&gt; &lt;p&gt;The reason you need to take special steps to enable IPv6 is that Podman went through a major architectural change in version 4.0. The new network stack, which has been rewritten from scratch in Rust, is composed of two tools:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Netavark:&lt;/strong&gt; A network setup tool that configures network bridges, firewall rules, and system settings to give containers access to external networks&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Aardvark:&lt;/strong&gt; An authoritative DNS server for A and AAAA container records, enabling containers to resolve connections to other containers by their names or aliases.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Both these tools work together to enable container networking with IPv6, but they are not enabled by default.&lt;/p&gt; &lt;p&gt;For more information about the new network stack, please refer to the article &lt;a href="https://www.redhat.com/sysadmin/podman-new-network-stack"&gt;Podman 4.0's new network stack: What you need to know&lt;/a&gt;.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: Podman v4.0 performs several schema migrations in the Podman database during the first run. These schema migrations prevent Podman v3.x and earlier from reading some network configuration information from the database. Therefore, downgrading from Podman v4.0 to an earlier version will cause containers to lose their static IP, MAC address, and port bindings.&lt;/p&gt; &lt;h2&gt;Package installation and configuration&lt;/h2&gt; &lt;p&gt;If you're using Red Hat Enterprise Linux 8.6, you'll need to take a few additional steps to install the Netavark backend; in Red Hat Enterprise Linux 9, Netavark is installed along with the Podman package.&lt;/p&gt; &lt;h3&gt;Install Podman 4.0 on Red Hat Enterprise Linux 8.6&lt;/h3&gt; &lt;p&gt;Before upgrading the Podman package from v3.x to 4.x on RHEL 8.6, you should remove all non-default defined networks. You can recreate them after the package upgrade.&lt;/p&gt; &lt;p&gt;On RHEL 8.6, by default Podman will use the Container Network Interface (CNI) backend. In order to use Netavark instead, you must explicitly mention it during installation, as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;[root@atomic-test ~]# yum install podman netavark -y&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The Aardvark package will be installed as a dependency of the Netavark package, so you don't have to mention it in the command.&lt;/p&gt; &lt;p&gt;Then copy the &lt;code&gt;containers.conf&lt;/code&gt; file to &lt;code&gt;/etc/containers/&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;[root@atomic-test ~]# cp /usr/share/containers/containers.conf /etc/containers/containers.conf&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Edit &lt;code&gt;/etc/containers/containers.conf&lt;/code&gt; and find the following line under the &lt;code&gt;[network]&lt;/code&gt; section:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;network_backend = "cni"&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Change that line to:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;network_backend = "netavark"&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can issue the following commands to verify that Podman will use the Netavark backend:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;[root@atomic-test ~]# podman info |grep -i networkbackend networkBackend: netavark [root@atomic-test ~]# cat /var/lib/containers/storage/defaultNetworkBackend netavark&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Install Podman 4.0 on Red Hat Enterprise Linux 9&lt;/h3&gt; &lt;p&gt;If you're using RHEL 9, the process is much simpler. The Netavark backend is installed along with Podman with the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt; [root@atomic-test ~]# yum install podman -y &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;The Netavark and Aardvark packages are installed as dependencies of Podman, so you don't have to mention them in the command. And Podman uses Netavark as the network backend by default in RHEL 9, so no further configuration is required.&lt;/p&gt; &lt;h2&gt;Create an interface that supports the dual IPv4/IPv6 stack&lt;/h2&gt; &lt;p&gt;The default bridge, &lt;code&gt;podman0&lt;/code&gt;, supports only the IPv4 stack, and DNS is disabled. A look at the default stack shows that IPv6 and DNS are disabled:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;# podman network inspect podman [ { "name": "podman", "id": "2f259bab93aaaaa2542ba43ef33eb990d0999ee1b9924b557b7be53c0b7a1bb9", "driver": "bridge", "network_interface": "podman0", "created": "2022-06-24T18:49:34.800035098+05:30", "subnets": [ { "subnet": "10.88.0.0/16", "gateway": "10.88.0.1" } ], "ipv6_enabled": false, "internal": false, "dns_enabled": false, "ipam_options": { "driver": "host-local" } } ]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You must therefore create a new bridge that supports IPv6 addresses and DNS. Here, we'll name this bridge &lt;code&gt;podman1&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;[root@atomic-test ~]# podman network create --ipv6 podman1&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Examine the new bridge by issuing this command:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;[root@atomic-test ~]# podman network inspect podman1&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This snippet from the output shows the use of IPv6:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt; { "subnet": "fd96:7c2e:b8d2:bf65::/64", "gateway": "fd96:7c2e:b8d2:bf65::1" } ], "ipv6_enabled": true,&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Now create a network interface by specifying the network range for both IPv4 and IPv6:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;[root@atomic-test ~]# podman network create --ipv6 --gateway fd00::1:8:1 --subnet fd00::1:8:0/112 --gateway 10.90.0.1 --subnet 10.90.0.0/16 podman1&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Attach a pod to the Podman network interface&lt;/h2&gt; &lt;p&gt;Podman is now configured to handle pods using IPv6. Run a sample pod as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;[root@atomic-test ~]# podman run --network podman1 -d -p 8080:80 docker.io/fedora/apache&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Expose the pod with a static IPv6 address, using the new &lt;code&gt;--ip6&lt;/code&gt; option:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;[root@atomic-test ~]# podman run --network podman1 -d --ip6 fd00::1:8:9 -p 8080:80 docker.io/fedora/apache&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Port mapping&lt;/h2&gt; &lt;p&gt;To make the container service reachable from an outside network, Netavark creates appropriate masquerade rules in iptables. For the static pod created in the previous section, let's take a quick look at the associated DNAT rules using the following &lt;code&gt;iptables&lt;/code&gt; command:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt; iptables -t nat -L -n -v &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;The output should look like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;Chain PREROUTING (policy ACCEPT) target prot opt source destination NETAVARK-HOSTPORT-DNAT all ::/0 ::/0 ADDRTYPE match dst-type LOCAL Chain NETAVARK-HOSTPORT-DNAT (2 references) target prot opt source destination NETAVARK-DN-F11DC6A6D09CF tcp ::/0 ::/0 tcp dpt:8080 /* dnat name: podman1 id: 8de28bebed939bb6449fe3d97cce5ae2e4a785462bb9ffa8d1417143f809bff0 */ Chain NETAVARK-DN-F11DC6A6D09CF (1 references) target prot opt source destination NETAVARK-HOSTPORT-SETMARK tcp fd00::1:8:0/112 ::/0 tcp dpt:8080 NETAVARK-HOSTPORT-SETMARK tcp ::1 ::/0 tcp dpt:8080 DNAT tcp ::/0 ::/0 tcp dpt:8080 to:[fd00::1:8:9]:80&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When a packet destined for container port 8080 enters the host network, the packet is first processed by the iptables &lt;code&gt;PREROUTING&lt;/code&gt; chain. Packets are then further processed by the &lt;code&gt;NETAVARK-HOSTPORT-DNAT&lt;/code&gt; chain (the only custom chain defined in the &lt;code&gt;PREROUTING&lt;/code&gt; chain). Depending on the port used, packets are further processed by the port-specific DNAT chain &lt;code&gt;NETAVARK-DN-F11DC6A6D09CF&lt;/code&gt; defined in &lt;code&gt;NETAVARK-DN-F11DC6A6D09CF&lt;/code&gt;. Packets are then sent to the appropriate container.&lt;/p&gt; &lt;h2&gt;Aardvark DNS server&lt;/h2&gt; &lt;p&gt;Aardvark keeps track of the containers and their assigned IP addresses based on the network interface to which the pod has been attached. Containers attached to the same network are resolvable using their names.&lt;/p&gt; &lt;p&gt;The following example uses the &lt;code&gt;podman1&lt;/code&gt; bridge we previously created:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;[root@atomic-test ~]# ls /run/containers/networks/aardvark-dns/ aardvark.pid podman &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Like DNS zone records, Aardvark keeps track of what is similar to DNS A/AAA records. The mapping of container names to IP addresses is stored in this file. If a container is not reachable using its container name, you can refer to this file to see if a record has been created for that container.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;/run/containers/networks/aardvark-dns/podman1&lt;/code&gt; file shows DNS records for &lt;code&gt;podman1&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;fd00::1:8:1 0f6d61bb7f6e8dcb4b8586ebc90d699b0e988406240419e8e48e1082ffd00451 fd00::1:8:2 goofy_cannon,0f6d61bb7f6e 0f6d61bb7f6e8dcb4b8586ebc90d699b0e988406240419e8e48e1082ffd00451 10.90.0.2 goofy_cannon,0f6d61bb7f6e 75647734d979ab6ded5636741ccd794fd1845fe0d5ef7161071fe9bd93d7f1fa fd00::1:8:9 test1,75647734d979 75647734d979ab6ded5636741ccd794fd1845fe0d5ef7161071fe9bd93d7f1fa 10.90.0.3 test1,75647734d979 e394edc2e5bda1e790785d07eb32f8ec72e010f0dac5978e2152df472291d715 fd00::1:8:10 test2,e394edc2e5bd e394edc2e5bda1e790785d07eb32f8ec72e010f0dac5978e2152df472291d715 10.90.0.4 test2,e394edc2e5bd&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Whenever a pod is deleted, Aardvark removes the entry from its database.&lt;/p&gt; &lt;h2&gt;Rootless containers&lt;/h2&gt; &lt;p&gt;Rootless containers continue to use the &lt;a href="https://github.com/rootless-containers/slirp4netns"&gt;slirp4netns&lt;/a&gt; service for communication. To expose the container service externally, slirp4netns listens on the host network according to the port mapping configuration. We want rootless containers to be reachable using IPV6 addresses as well.&lt;/p&gt; &lt;p&gt;By default, when a Podman container is started, it does not get an IP address. Containers within the host should be reachable using the mapped port in the format &lt;code&gt;host_ip&lt;/code&gt;:&lt;code&gt;port&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;For rootless containers, you can define custom Podman network interfaces as the rootless user and then attach the pod to them. Containers should be reachable within the host using the container IP address.&lt;/p&gt; &lt;p&gt;To enable IPv6 addresses with a custom network, enter:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;[awx@atomic-test ~]$ podman network create --ipv6 redhat &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Inspect the newly created &lt;code&gt;redhat&lt;/code&gt; interface as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;[awx@atomic-test ~]$ podman network inspect redhat [ { "name": "redhat", "id": "262e49487783d58774dfa5f581e07849583558c059416d014774317ffc4190a7", "driver": "bridge", "network_interface": "podman1", "created": "2022-06-29T05:30:24.968361698-04:00", "subnets": [ { "subnet": "10.89.0.0/24", "gateway": "10.89.0.1" }, { "subnet": "fd25:1552:57a6:f8ee::/64", "gateway": "fd25:1552:57a6:f8ee::1" } ], "ipv6_enabled": true, "internal": false, "dns_enabled": true, "ipam_options": { "driver": "host-local" } } ]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Attach a rootless container to the custom network with a static IPv6 address as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="bash"&gt;[awx@atomic-test ~]$ podman run --network redhat -d --ip6 fd25:1552:57a6:f8ee::10 -p 8081:80 docker.io/fedora/apache&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Rootless containers within the host should be reachable by their own IP address or by a static IP address. External communication for such containers will continue to be handled by slirp4netns.&lt;/p&gt; &lt;p&gt;Aardvark DNS is enabled only for custom network interfaces, created using &lt;code&gt;podman network create&lt;/code&gt;. Aardvark takes care of resolution for rootless containers using their respective container names attached to the same custom network interface.&lt;/p&gt; &lt;h2&gt;More in Podman 4.0&lt;/h2&gt; &lt;p&gt;Along with IPv6 support, the new network stack included with Podman v4.0 features improved support for containers in multiple networks and improved performance. Podman also continues to support the CNI stack. There are several other features which are not discussed here, such as the &lt;code&gt;podman network connect&lt;/code&gt; command, which allows you to connect a running container to another network. So explore the shiny new network stack, and leave a comment on this article if you have thoughts about the improvements in IPv6 support.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/08/10/how-conifgure-podman-40-ipv6" title="How to configure Podman 4.0 for IPv6"&gt;How to configure Podman 4.0 for IPv6&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Ranjith Rajaram</dc:creator><dc:date>2022-08-10T07:00:00Z</dc:date></entry><entry><title type="html">Infinispan 14.0.0.CR1</title><link rel="alternate" href="https://infinispan.org/blog/2022/08/09/infinispan-14" /><author><name>Tristan Tarrant</name></author><id>https://infinispan.org/blog/2022/08/09/infinispan-14</id><updated>2022-08-09T12:00:00Z</updated><content type="html">Dear Infinispan community, Infinispan 14 candidate release 1 is here! Here is your chance to verify your application against our latest and greatest and tell us if things are working as expected or if there are any showstoppers we should address before tagging the final release. AARCH64 IMAGES We are now building images for AArch64 (aka ARM64) by default, which allow you to run Infinispan on Apple Silicon, Amazon Graviton and other ARM CPU platforms without resorting to emulation. PROTOBUF ONEOF SUPPORT Protostream has been updated to support ProtoBuf 3’s oneof keyword. CONSOLE When creating a new cache, it’s now possible to choose the key/value types from the list of available protobuf schemas. CLI The CLI can now connect to a server secured with client certificate authentication. The config command now supports the keystore and keystore-password to persist the client certificate configuration. Additionally, the new config reset command offers a quick way to reset all configuration properties to their default values. RELEASE NOTES You can look at the to see what has changed. Get them from our .</content><dc:creator>Tristan Tarrant</dc:creator></entry><entry><title>8 elements of securing Node.js applications</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/08/09/8-elements-securing-nodejs-applications" /><author><name>Lucas Holmquist</name></author><id>2526777f-7b53-4a26-88f8-8bf100b7ef8e</id><updated>2022-08-09T07:00:00Z</updated><published>2022-08-09T07:00:00Z</published><summary type="html">&lt;p&gt;Making your &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js&lt;/a&gt; applications secure is an essential part of the development of Node.js modules and applications. Security practices apply to both the code itself and your software development process. This installment of the ongoing &lt;a href="https://github.com/nodeshift/nodejs-reference-architecture"&gt;Node.js Reference Architecture&lt;/a&gt; series focuses on some of the key security elements that &lt;a href="https://developers.redhat.com/topics/javascript"&gt;JavaScript&lt;/a&gt; developers should address.&lt;/p&gt; &lt;p&gt;Read the series so far:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Part 1: &lt;a href="https://developers.redhat.com/blog/2021/03/08/introduction-to-the-node-js-reference-architecture-part-1-overview"&gt;Overview of the Node.js reference architecture&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 2: &lt;a href="https://developer.ibm.com/blogs/nodejs-reference-architectire-pino-for-logging/"&gt;Logging in Node.js&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 3: &lt;a href="https://developers.redhat.com/articles/2021/05/17/introduction-nodejs-reference-architecture-part-3-code-consistency"&gt;Code consistency in Node.js&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 4: &lt;a href="https://developers.redhat.com/articles/2021/06/22/introduction-nodejs-reference-architecture-part-4-graphql-nodejs"&gt;GraphQL in Node.js&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 5: &lt;a href="https://developers.redhat.com/articles/2021/08/26/introduction-nodejs-reference-architecture-part-5-building-good-containers"&gt;Building good containers&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 6: &lt;a href="https://developers.redhat.com/articles/2021/12/03/introduction-nodejs-reference-architecture-part-6-choosing-web-frameworks"&gt;Choosing web frameworks&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 7: &lt;a href="https://developers.redhat.com/articles/2022/03/02/introduction-nodejs-reference-architecture-part-7-code-coverage"&gt;Code Coverage&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Part 8: &lt;a href="https://developers.redhat.com/articles/2022/04/11/introduction-nodejs-reference-architecture-part-8-typescript"&gt;Typescript&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;This article covers eight key elements of building security into your software development process to make your Node.js applications and modules robust:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Choosing dependencies&lt;/li&gt; &lt;li&gt;Managing access and content of public and private data stores such as npm and GitHub&lt;/li&gt; &lt;li&gt;Writing defensive code&lt;/li&gt; &lt;li&gt;Limiting required execution privileges&lt;/li&gt; &lt;li&gt;Support for logging and monitoring&lt;/li&gt; &lt;li&gt;Externalizing secrets&lt;/li&gt; &lt;li&gt;Maintaining a secure and up-to-date foundation for deployed applications&lt;/li&gt; &lt;li&gt;Maintaining individual modules&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Although this is not necessarily an exhaustive list, these are commonly the focus of the Red Hat and IBM teams.&lt;/p&gt; &lt;h2&gt;1. Choosing third-party dependencies&lt;/h2&gt; &lt;p&gt;Most Node.js applications and modules have third-party dependencies, many of which contain security vulnerabilities. Although open source teams usually fix the vulnerabilities soon after discovery, there are still gaps in time before an application developer learns about the vulnerability and puts the fixed library into production. Attackers might exploit the compromised program during those times. So it is important to choose dependencies carefully and regularly evaluate if they remain the right choices for you.&lt;/p&gt; &lt;p&gt;A couple of helpful tips in this area are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Determine that a dependency is necessary before integrating it into your application. Is using the modules instead of your code saving development and maintenance time?&lt;/li&gt; &lt;li&gt;Avoid code one-liners.&lt;/li&gt; &lt;li&gt;If you have a choice of dependencies, use one that has only a few or no dependencies of its own.&lt;/li&gt; &lt;li&gt;Choose dependencies that already have a high level of usage based on statistics, such as GitHub stars and npm. These tend to be maintained well.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Find more in-depth guidance on managing dependencies in the reference architecture's &lt;a href="https://github.com/nodeshift/nodejs-reference-architecture/blob/main/docs/development/dependencies.md" target="_blank"&gt;choosing and vetting dependencies&lt;/a&gt; section.&lt;/p&gt; &lt;h2&gt;2. Managing access and content of public and private data stores&lt;/h2&gt; &lt;p&gt;Modern development flows often use public and private data stores, including npm and GitHub. We recommend the following management practices:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Enable two-factor authentication (2FA) to ensure the integrity of the committed code and published assets. GitHub, for instance, now requires a developer who logs in to verify their identity through a code sent to their device.&lt;/li&gt; &lt;li&gt;Use files such as &lt;code&gt;.npmignore&lt;/code&gt; and &lt;code&gt;.gitignore&lt;/code&gt; to avoid accidentally publishing secrets. These are hidden files consulted by programs (npm and Git, respectively). If you list a file with your secrets in one of these hidden files, npm and Git will never check it into the source repository. Of course, you must have a separate process to manage the secrets. There are many services available to help you.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;A &lt;code&gt;.npmrc&lt;/code&gt; file is often needed for npm installations, particularly if you have private modules. Avoid leaking information in the &lt;code&gt;.npmrc&lt;/code&gt; file when building containers by using one of these options:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Use two-stage builds, where you build one image with all the tools for the application and a second to create a stripped-down image. In addition to saving memory and disk space, the two-stage build allows you to omit the &lt;code&gt;.npmrc&lt;/code&gt; file from the final image that goes into production.&lt;/li&gt; &lt;li&gt;Avoid adding the secrets to any image in the build process. Instead, you can securely mount secrets into containers during the build process, as explained in the article &lt;a href="https://projectatomic.io/blog/2018/06/sneak-secrets-into-containers"&gt;How to sneak secrets into your containers&lt;/a&gt;. In particular, &lt;a href="https://buildah.io"&gt;Buildah&lt;/a&gt; has built-in functions to make it easier to mount files with secrets.&lt;/li&gt; &lt;li&gt;The least preferred method:  Delete the &lt;code&gt;.npmrc&lt;/code&gt; file from the final image and compress images to flatten layers.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;3. Writing defensive code&lt;/h2&gt; &lt;p&gt;Secure coding often calls for special training and cannot be summarized in simple precepts. Nevertheless, you can eliminate many common vulnerabilities by following the recommendations in this section. There is a more extensive list in the &lt;a href="https://github.com/nodeshift/nodejs-reference-architecture/blob/main/docs/development/secure-development-process.md"&gt;Secure Development Process&lt;/a&gt; section of the reference architecture.&lt;/p&gt; &lt;h3&gt;Avoid global state&lt;/h3&gt; &lt;p&gt;Using global variables makes it easy to leak information between requests accidentally. With global variables, data from one web visitor might be in memory when a second visitor sends a request. Potential impacts include corrupting the request or revealing private information to another visitor.&lt;/p&gt; &lt;p&gt;Each request should encapsulate its data. If you need global data, such as statistics about the traffic you are handling, store it in an external database. This solution is preferable to global variables because the data in the database is persistent.&lt;/p&gt; &lt;h3&gt;Set the NODE_ENV environment variable to production&lt;/h3&gt; &lt;p&gt;Some packages consult the NODE_ENV environment variable to decide whether they need to lock things down or share less information. Therefore, setting the variable to &lt;code&gt;production&lt;/code&gt; is the safest setting and should be used all the time. The application developer, not the package, should determine what information to display.&lt;/p&gt; &lt;h3&gt;Validate user input&lt;/h3&gt; &lt;p&gt;Unvalidated input can result in attacks such as command injection, SQL injection, and denial of service, disrupting your service and corrupting data. Always validate user input before implementing it within your application code. Make sure you validate input on the server even if you validate on the client side (browser or mobile application) because an attacker could send requests directly to the APIs without using the client.&lt;/p&gt; &lt;h3&gt;Include good exception handling&lt;/h3&gt; &lt;p&gt;Basic practices for handling exceptions include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Check at a high level for missed exceptions and handle them gracefully. Make sure to have a default handler for &lt;a href="https://expressjs.com"&gt;Express&lt;/a&gt; and other web frameworks to avoid displaying errors with the stack trace to the visitor.&lt;/li&gt; &lt;li&gt;Listen to errors when using &lt;a href="https://nodejs.dev/learn/the-nodejs-event-emitter"&gt;EventEmitters&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Check for errors passed into asynchronous calls.&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Avoid complex regular expressions&lt;/h3&gt; &lt;p&gt;Regular expressions help with text parsing tasks, such as ensuring that a visitor submitted their email address or phone number in an acceptable format or checking input for suspicious characters that could signal an attack. Unfortunately, if a regular expression is complex, it can take a long time to run. In fact, some regexes run essentially forever on certain kinds of text.&lt;/p&gt; &lt;p&gt;Even worse, although your regular expression might operate reasonably under most input, a malicious attacker could provide content that triggers an endless run. The article &lt;a href="https://owasp.org/www-community/attacks/Regular_expression_Denial_of_Service_-_ReDoS"&gt;Regular expression Denial of Service - ReDoS&lt;/a&gt; explains this type of vulnerability.&lt;/p&gt; &lt;p&gt;The takeaway is to be careful about the complexity of any regular expression you use.  When checking text input, avoid regular expressions or use only simple ones that check for issues such as invalid characters.&lt;/p&gt; &lt;h3&gt;Limit the attack surface&lt;/h3&gt; &lt;p&gt;Some helpful ways to limit the available attack surface are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Expose only the APIs needed to support the intended operations. For example, when using Express, remove any unnecessary routes.&lt;/li&gt; &lt;li&gt;Group all external endpoints under a prefix (i.e., &lt;code&gt;/api&lt;/code&gt;). This makes it easier to expose only APIs intended to be external in the ingress configuration.&lt;/li&gt; &lt;li&gt;Don't rewrite paths to the root (&lt;code&gt;/&lt;/code&gt;).&lt;/li&gt; &lt;li&gt;Use authentication to limit access. When possible, integrate an organizational identity and access control provider instead of implementing your own.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;4. Limiting required execution privileges&lt;/h2&gt; &lt;p&gt;Design your applications to run with the minimum privileges required. Ensure that your applications can run as a non-root user, especially when deployed within containers. The user and group under which the application runs should have access only to a minimal set of files and resources. For more container recommendations, check out part five of this series:  &lt;a href="https://developers.redhat.com/articles/2021/08/26/introduction-nodejs-reference-architecture-part-5-building-good-containers"&gt;Building good containers&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;5. Support for logging and monitoring&lt;/h2&gt; &lt;p&gt;Logging sensitive or suspicious actions will make it easier for monitoring tools to collect and analyze the data. See the &lt;a href="https://github.com/nodeshift/nodejs-reference-architecture/blob/main/docs/operations/logging.md"&gt;logging&lt;/a&gt; section of the reference architecture for recommended monitoring packages.&lt;/p&gt; &lt;h2&gt;6. Externalizing secrets&lt;/h2&gt; &lt;p&gt;Secrets (i.e., passwords) should be defined externally and made available to the application at runtime through secure means. Make sure you don't commit secrets in code repositories or build them into container images.&lt;/p&gt; &lt;p&gt;The article &lt;a href="https://cloud.redhat.com/blog/gitops-secret-management"&gt;GitOps secret management&lt;/a&gt; provides a good overview of the techniques and components used to manage externalized secrets. The article also refers to additional articles on the topic.&lt;/p&gt; &lt;p&gt;More specific to Node.js deployments, consider using the &lt;a href="https://www.npmjs.com/package/dotenv"&gt;dotenv&lt;/a&gt; package, which is popular among our team. We also contribute to &lt;a href="https://www.npmjs.com/package/kube-service-bindings"&gt;kube-service-bindings&lt;/a&gt; to support the &lt;a href="https://github.com/servicebinding/spec"&gt;Service Binding Specification for Kubernetes&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;One of the leading tools for managing externalized secrets is &lt;a href="https://www.npmjs.com/package/node-vault"&gt;node-vault&lt;/a&gt;. Teams involved in deployments with the IBM cloud find the &lt;a href="https://www.npmjs.com/package/@ibm-cloud/secrets-manager"&gt;IBM Cloud Secrets Manager Node.js SDK&lt;/a&gt; helpful.&lt;/p&gt; &lt;h2&gt;7. Maintaining a secure and up-to-date foundation for deployed applications&lt;/h2&gt; &lt;p&gt;A Node.js application is on top of several components. You must keep this foundation secure and up to date throughout your application's lifetime, even if no code changes within your application.&lt;/p&gt; &lt;p&gt;The key elements include secure and up-to-date:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;base container images&lt;/li&gt; &lt;li&gt;Node.js runtime&lt;/li&gt; &lt;li&gt;dependencies&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Based on the team's experience, here are some recommended tips:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Take advantage of container images that come with Node.js already bundled in. The maintainers usually release an update after fixing a &lt;a href="https://www.cve.org"&gt;CVE&lt;/a&gt; reported against the Node.js runtime or any other components within the container. This is one of the reasons the team members often use the &lt;a href="https://catalog.redhat.com/software/containers/ubi8/nodejs-16/615aee9fc739c0a4123a87e1"&gt;ubi/nodejs&lt;/a&gt; container images.&lt;/li&gt; &lt;li&gt;If you build Node.js binaries into a base image, subscribe to and read the &lt;a href="https://groups.google.com/g/nodejs-sec"&gt;nodejs-sec&lt;/a&gt; mailing list. This low-volume mailing list provides advance notice of security releases and will give you the earliest warning to update your Node.js version.&lt;/li&gt; &lt;li&gt;If you use common dependencies across many projects, create a dependency image from which each project reads. While this centralization is suitable for build times, as outlined in the &lt;a href="https://github.com/nodeshift/nodejs-reference-architecture/blob/main/docs/development/building-good-containers.md#dependency-image"&gt;dependency image&lt;/a&gt; section of the reference architecture, it also helps reduce the total work required for dependency updates when shared across numerous projects.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;For a more exhaustive list of tips, check out the &lt;a href="https://github.com/nodeshift/nodejs-reference-architecture/blob/main/docs/development/secure-development-process.md"&gt;Secure Development Process&lt;/a&gt; section of the reference architecture.&lt;/p&gt; &lt;h2&gt;8. Maintaining individual modules&lt;/h2&gt; &lt;p&gt;When you maintain modules in GitHub, enable &lt;a href="https://docs.snyk.io/integrations/git-repository-scm-integrations/github-integration"&gt;Snyk integration&lt;/a&gt; and review the pull requests it creates.&lt;/p&gt; &lt;p&gt;It is also important to test and ensure the module runs and passes tests on the latest Long Term Support (LTS) version of Node.js. Automated testing reduces risk when Node.js security releases require updates.&lt;/p&gt; &lt;h2&gt;Coming next&lt;/h2&gt; &lt;p&gt;We plan to cover new topics regularly as part of the &lt;a href="https://developers.redhat.com/blog/2021/03/08/introduction-to-the-node-js-reference-architecture-part-1-overview/"&gt;Node.js reference architecture series&lt;/a&gt;. Until the next installment, we invite you to visit the &lt;a href="https://github.com/nodeshift/nodejs-reference-architecture"&gt;Node.js reference architecture repository&lt;/a&gt; on GitHub, where you will see the work we have done and look forward to future topics.&lt;/p&gt; &lt;p&gt;To learn more about what Red Hat is up to on the Node.js front, check out our &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js page&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/08/09/8-elements-securing-nodejs-applications" title="8 elements of securing Node.js applications"&gt;8 elements of securing Node.js applications&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Lucas Holmquist</dc:creator><dc:date>2022-08-09T07:00:00Z</dc:date></entry><entry><title type="html">Eclipse Vert.x 4.3.3 released!</title><link rel="alternate" href="https://vertx.io/blog/eclipse-vert-x-4-3-3" /><author><name>Julien Viet</name></author><id>https://vertx.io/blog/eclipse-vert-x-4-3-3</id><updated>2022-08-09T00:00:00Z</updated><content type="html">Eclipse Vert.x version 4.3.3 has just been released. It fixes quite a few bugs that have been reported by the community and provides a couple of features. In addition it provides support for virtual threads incubation project.</content><dc:creator>Julien Viet</dc:creator></entry><entry><title>OpenTelemetry: A Quarkus Superheroes demo of observability</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/08/08/opentelemetry-quarkus-superheroes-demo-observability" /><author><name>Eric Deandrea</name></author><id>5adfbbc9-3385-45b5-8707-eff82e74941a</id><updated>2022-08-08T07:00:00Z</updated><published>2022-08-08T07:00:00Z</published><summary type="html">&lt;p&gt;Are you building &lt;a href="https://developers.redhat.com/topics/microservices-for-java-developers"&gt;microservices&lt;/a&gt;? Do you struggle with observability and with capturing telemetry data between distributed services? This article shows how to quickly and easily introduce &lt;a href="http://opentelemetry.io"&gt;OpenTelemetry&lt;/a&gt; into a distributed system built on &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; with &lt;a href="https://developers.redhat.com/products/quarkus/overview"&gt;Quarkus&lt;/a&gt;. This combination allows you to visualize the interactions between all the microservices within an overall system.&lt;/p&gt; &lt;p&gt;The article introduces the official Quarkus sample application, &lt;a href="https://quarkus.io/blog/quarkus-superheroes-to-the-rescue"&gt;Quarkus Superheroes&lt;/a&gt;, deploys it on the free &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt;, and demonstrates how to collect and visualize telemetry data in order to observe microservices' behavior.&lt;/p&gt; &lt;h2&gt;What is OpenTelemetry?&lt;/h2&gt; &lt;p&gt;The &lt;a href="http://opentelemetry.io"&gt;OpenTelemetry website&lt;/a&gt; states that "OpenTelemetry is a collection of tools, APIs, and SDKs. Use it to instrument, generate, collect, and export telemetry data (metrics, logs, and traces) to help you analyze your software's performance and behavior."&lt;/p&gt; &lt;p&gt;OpenTelemetry was created by merging the popular &lt;a href="https://opentracing.io"&gt;OpenTracing&lt;/a&gt; and &lt;a href="https://opencensus.io"&gt;OpenCensus&lt;/a&gt; projects. It is a standard that integrates with many open source and commercial products written in many programming languages. Implementations of OpenTelemetry are in varying stages of maturity.&lt;/p&gt; &lt;p&gt;At its core, OpenTelemetry contains the &lt;a href="https://opentelemetry.io/docs/collector"&gt;Collector&lt;/a&gt;, a vendor-agnostic way to receive, process, and export telemetry data. Figure 1 displays the Collector's high-level architecture.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/1-otel-collector.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/1-otel-collector.png?itok=UOu_EeNu" width="984" height="698" alt="The OpenTelemetry Collector processes input in receivers and sends output through exporters." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: The OpenTelemetry Collector processes input in receivers and sends output through exporters. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;For more information about observability and OpenTelemetry, check out the excellent article, &lt;a href="https://developers.redhat.com/articles/2022/04/12/observability-2022-why-it-matters-and-how-opentelemetry-can-help"&gt;Observability in 2022: Why it matters and how OpenTelemetry can help&lt;/a&gt; by &lt;a href="https://developers.redhat.com/author/ben-evans"&gt;Ben Evans&lt;/a&gt;. In addition, &lt;a href="https://developers.redhat.com/author/daniel-oh"&gt;Daniel Oh&lt;/a&gt;'s article about &lt;a href="https://developers.redhat.com/articles/2022/06/21/distributed-tracing-opentelemetry-knative-and-quarkus"&gt;integrating OpenTelemetry into Quarkus applications running on Knative&lt;/a&gt; is a great read.&lt;/p&gt; &lt;p&gt;Now let's discuss how OpenTelemetry can help you observe the Quarkus Superheroes application.&lt;/p&gt; &lt;h2&gt;Prerequisites for the Quarkus Superheroes application&lt;/h2&gt; &lt;p&gt;You can easily deploy the Quarkus Superheroes application on any &lt;a href="https://github.com/quarkusio/quarkus-super-heroes#deploying-to-kubernetes"&gt;Kubernetes instance&lt;/a&gt;. Here we deploy the application on the &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt; because it is easy to obtain a free account and the environment requires minimal setup. But you can adapt the instructions in this article to other Kubernetes environments.&lt;/p&gt; &lt;p&gt;To follow along on your own with the steps in this demonstration, you will need:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;A free Red Hat account to access the Developer Sandbox. Signing up does not require a credit card. &lt;/li&gt; &lt;li&gt;The &lt;a href="https://docs.openshift.com/container-platform/4.10/cli_reference/openshift_cli/getting-started-cli.html"&gt;Red Hat OpenShift &lt;code&gt;oc&lt;/code&gt; command-line interface&lt;/a&gt; (CLI).&lt;/li&gt; &lt;li&gt;A Java development environment. In this article, we will use the &lt;a href="https://developers.redhat.com/articles/2021/12/14/explore-java-17-language-features-quarkus"&gt;Java 17&lt;/a&gt; version of the application, but any of the other three versions (natively-compiled Java 11, JVM Java 11, or natively-compiled Java 17) would work the same.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;The Quarkus Superheroes sample application&lt;/h2&gt; &lt;p&gt;The &lt;a href="https://quarkus.io/blog/quarkus-superheroes-to-the-rescue"&gt;Quarkus Superheroes application&lt;/a&gt; consists of several microservices which co-exist to form an extensive system. Some microservices communicate synchronously via REST. Others are event-driven, producing and consuming events to and from &lt;a href="https://kafka.apache.org"&gt;Apache Kafka&lt;/a&gt;. Some microservices are reactive, whereas others are traditional. All the microservices produce metrics consumed by &lt;a href="https://prometheus.io"&gt;Prometheus&lt;/a&gt; and export tracing information to OpenTelemetry. The source code for the application is on &lt;a href="https://github.com/quarkusio/quarkus-super-heroes"&gt;GitHub&lt;/a&gt; under an Apache 2.0 license.&lt;/p&gt; &lt;p&gt;Figure 2 shows the overall architecture of this application.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/2-superheroes-architecture.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/2-superheroes-architecture.png?itok=wRGUrPu8" width="840" height="959" alt="The Quarkus Superheroes architecture is complex, including communication between components with HTTP and communicating with the Collector through gRPC." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: The Quarkus Superheroes architecture is complex, including communication between components with HTTP and communicating with the Collector through gRPC. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;Detailed information about the application and its architecture can be found on the &lt;a href="https://quarkus.io/blog/quarkus-superheroes-to-the-rescue"&gt;quarkus.io blog&lt;/a&gt;. One of the &lt;a href="https://quarkus.io/blog/quarkus-superheroes-to-the-rescue/#requirements"&gt;main requirements&lt;/a&gt; when building the application was that it should be simple to deploy on &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;A Prometheus instance scrapes metrics from all of the application services. Additionally, all of the services export telemetry data to the OpenTelemetry Collector. The Collector, in turn, exports telemetry data to a &lt;a href="https://www.jaegertracing.io"&gt;Jaeger&lt;/a&gt; instance, where the data can be analyzed and visualized. The &lt;a href="https://grpc.io"&gt;gRPC protocol&lt;/a&gt; is used for communication between the applications and the OpenTelemetry Collector and between the OpenTelemetry Collector and Jaeger.&lt;/p&gt; &lt;h2&gt;Deploying the application on the OpenShift Sandbox&lt;/h2&gt; &lt;p&gt;The &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;OpenShift Sandbox&lt;/a&gt; provides a private OpenShift environment &lt;a href="https://developers.redhat.com/openshift"&gt;free for 30 days&lt;/a&gt;. It is in a shared, multi-tenant OpenShift cluster preconfigured with a set of developer tools. This private environment includes two projects (namespaces) and a resource quota of 7GB RAM and 15GB storage. The application's development and stage phases can be emulated using the two namespaces. All your &lt;code&gt;Pod&lt;/code&gt;s automatically scale to 0 after 12 hours.&lt;/p&gt; &lt;p&gt;The following subsections set you up to use the Sandbox.&lt;/p&gt; &lt;h3&gt;Logging into the Sandbox&lt;/h3&gt; &lt;p&gt;You can access your Developer Sandbox with your Red Hat account. &lt;a href="https://redhat-scholars.github.io/managed-kafka-service-registry-workshop/managed-kafka-service-registry-workshop/main/03-quarkus-app-with-kafka-service-registry.html#devsandboxaccess"&gt;Follow these instructions&lt;/a&gt; to log in. Don't worry if you haven't created a Red Hat account yet. The instructions will guide you through creating and verifying a new account.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: Follow only the six steps in the "Get access to the Developer Sandbox" section of the instructions.&lt;/p&gt; &lt;h3&gt;Connecting your local machine to the Sandbox&lt;/h3&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/2021/04/21/access-your-developer-sandbox-for-red-hat-openshift-from-the-command-line"&gt;Follow these instructions&lt;/a&gt; to download the &lt;a href="https://docs.openshift.com/container-platform/4.10/cli_reference/openshift_cli/getting-started-cli.html"&gt;OpenShift CLI&lt;/a&gt; and run &lt;code&gt;oc login&lt;/code&gt; with the token from your sandbox. Then your terminal should be in the &lt;code&gt;&lt;your-username&gt;-dev&lt;/code&gt; project.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: If you already have a Developer Sandbox account and have existing workloads in your project, you might need to delete those before deploying the Quarkus Superheroes application. The Developer Sandbox limits the resources deployed at a single time for each user.&lt;/p&gt; &lt;h3&gt;Deploying the Quarkus Superheroes application&lt;/h3&gt; &lt;p&gt;The &lt;a href="https://github.com/quarkusio/quarkus-super-heroes/tree/main/deploy/k8s"&gt;deploy/k8s&lt;/a&gt; directory in the &lt;a href="https://github.com/quarkusio/quarkus-super-heroes"&gt;root of the application's GitHub repository&lt;/a&gt; contains Kubernetes descriptors for each of the four versions of the application: JVM 11, JVM 17, natively compiled with Java 11, and natively compiled with Java 17.&lt;/p&gt; &lt;p&gt;If you'd like, run &lt;code&gt;git clone&lt;/code&gt; to download the code from the &lt;a href="https://github.com/quarkusio/quarkus-super-heroes"&gt;Quarkus Superheroes GitHub repository&lt;/a&gt;. However, cloning is not necessary because you can apply Kubernetes resources directly from remote locations.&lt;/p&gt; &lt;p&gt;Perform the following steps in your terminal to deploy the Java 17 version of the &lt;a href="https://quay.io/quarkus-super-heroes"&gt;application container images&lt;/a&gt; and all the backing services. Wait for each step to complete before proceeding to the next one.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Deploy the applications by executing: &lt;pre&gt; &lt;code class="language-bash"&gt;oc apply -f https://raw.githubusercontent.com/quarkusio/quarkus-super-heroes/main/deploy/k8s/java17-openshift.yml&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Deploy the monitoring stack by executing: &lt;pre&gt; &lt;code class="language-bash"&gt;oc apply -f https://raw.githubusercontent.com/quarkusio/quarkus-super-heroes/main/deploy/k8s/monitoring-openshift.yml&lt;/code&gt;&lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt; &lt;p&gt;That's it! Deploying the Superheroes is super simple! Once everything deploys, your browser should look something like Figure 3.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/3-super-heroes-deployed.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/3-super-heroes-deployed.png?itok=r0xf1gq4" width="1042" height="913" alt="The OpenShift Topology view shows all the applications and services for the Quarkus Superheroes and the relationships between them." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: The OpenShift Topology view shows all the applications and services for the Quarkus Superheroes and the relationships between them. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;The system as deployed is not considered production-ready. The deployed resources (databases, Prometheus instance, OpenTelemetry Collector instance, Jaeger instance, Kafka broker, and schema registry) are not highly available and do not use Kubernetes operators for management or monitoring. They also use ephemeral storage.&lt;/p&gt; &lt;h2&gt;Interacting with the application&lt;/h2&gt; &lt;p&gt;Open the event statistics user interface (UI) by clicking the icon in the upper right corner of the &lt;code&gt;event-statistics&lt;/code&gt; application, shown in Figure 4.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/4-event-stats.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/4-event-stats.png?itok=IYfGUXMO" width="345" height="304" alt="Open the event statistics UI via the Open URL icon in OpenShift's Topology view." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4: Open the event statistics UI via the Open URL icon in OpenShift's Topology view. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;Once open, you should see the event statistics UI shown in Figure 5.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/5-event-stats-ui.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/5-event-stats-ui.png?itok=2LTUUzXn" width="913" height="246" alt="The statistics UI currently shows an empty statistics view before any battles are performed." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5: The statistics UI currently shows an empty statistics view before any battles are performed. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;Similarly, open the Superheroes UI by clicking the icon in the upper right corner of the &lt;code&gt;ui-super-heroes&lt;/code&gt; application, shown in Figure 6.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/6-open-super-heroes-ui.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/6-open-super-heroes-ui.png?itok=WSp0t8Bu" width="194" height="212" alt="Open the Superheroes UI via the Open URL icon in OpenShift's Topology view." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 6: Open the Superheroes UI via the Open URL icon in OpenShift's Topology view. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;Once open, you should see the Superheroes UI, shown in Figure 7. The following are clickable areas highlighted in green in Figure 7 :&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Expand or collapse the list of a Hero's or Villain's powers&lt;/li&gt; &lt;li&gt;Randomly select a new Hero and Villain for battle&lt;/li&gt; &lt;li&gt;Perform a battle&lt;/li&gt; &lt;/ul&gt; &lt;figure class="align-center" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/7-super-heroes-ui_0.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/7-super-heroes-ui_0.png?itok=lIG-ajEQ" width="600" height="490" alt=" The Superheroes UI during a fight shows a randomly-chosen Hero and Villain." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 7: The Superheroes UI during a fight shows a randomly-chosen Hero and Villain. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;Now you can perform a few battles with the same Hero and Villain and with different Heroes and Villains. Once you have completed a few battles, the table below the fighters displays a list of battles.&lt;/p&gt; &lt;p&gt;If you switch back to the event statistics UI, the slider should have moved or stayed in the middle if there were equal wins. There is also a list of the top ten winners and the number of wins for each team (see the example in Figure 8).&lt;/p&gt; &lt;figure class="align-center" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/8-stats.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/8-stats.png?itok=_E0EEhH2" width="908" height="293" alt="A screenshot of the statistics window showing results after several fights." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 8: After several fights, the statistics window shows the results. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;h2&gt;Analyzing telemetry data&lt;/h2&gt; &lt;p&gt;After performing a few battles, let's analyze the telemetry data. Open the Jaeger UI by clicking the icon in the upper right corner of the &lt;code&gt;jaeger&lt;/code&gt; application, shown in Figure 9. Once open, you should see the Jaeger UI.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/9-jaeger-ui-button.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/9-jaeger-ui-button.png?itok=3HrnXCC_" width="143" height="167" alt="Open the Jaeger UI via the Open URL icon in OpenShift's Topology view." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 9: Open the Jaeger UI via the Open URL icon in OpenShift's Topology view. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;h3&gt;Analyzing requests for new fighters&lt;/h3&gt; &lt;p&gt;First, let's analyze the traces generated when you requested new fighters. After you click the &lt;strong&gt;New Fighters&lt;/strong&gt; button in the Superheroes UI, the browser makes an HTTP request to the &lt;code&gt;/api/fights/randomfighters&lt;/code&gt; endpoint within the &lt;code&gt;rest-fights&lt;/code&gt; application. These services and operations should already be available in the Jaeger UI.&lt;/p&gt; &lt;p&gt;Next, in the Jaeger UI, select &lt;code&gt;rest-fights&lt;/code&gt; for the &lt;strong&gt;Service&lt;/strong&gt; and &lt;code&gt;/api/fights/randomfighters&lt;/code&gt; for the &lt;strong&gt;Operation&lt;/strong&gt; (see Figure 10).&lt;/p&gt; &lt;p&gt;Then click &lt;strong&gt;Find Traces&lt;/strong&gt;.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/10-jaeger-randomfighters.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/10-jaeger-randomfighters.png?itok=P8T_wDQa" width="308" height="704" alt="Fill out the Search boxes as indicated in the text for the /api/fights/randomfighters endpoint." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 10: Fill out the Search boxes as indicated in the text for the /api/fights/randomfighters endpoint. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;A list of traces should appear on the right-hand side of the Jaeger UI, as shown in Figure 11.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/11-jaeger-randomfighters-results_1.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/11-jaeger-randomfighters-results_1.png?itok=MRC6O49A" width="1043" height="367" alt="Traces for the /api/fights/randomfighters endpoint are shown." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 11: Traces for the /api/fights/randomfighters endpoint are shown. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;A trace consists of a series of &lt;em&gt;spans&lt;/em&gt;. Each span is a time interval representing a unit of work. Spans can have parent/child relationships and form a hierarchy. Spans can also indicate the parallelization of work running concurrently.&lt;/p&gt; &lt;p&gt;The bottom of Figure 11 shows that each trace contains 14 total spans: 6 spans in the &lt;code&gt;rest-fights&lt;/code&gt; application, 4 spans in the &lt;code&gt;rest-heroes&lt;/code&gt; application, and 4 spans in the &lt;code&gt;rest-villains&lt;/code&gt; application. Each trace also provides the total round-trip time of the request into the &lt;code&gt;/api/fights/randomfighters&lt;/code&gt; endpoint within the &lt;code&gt;rest-fights&lt;/code&gt; application and the total time spent within each unit of work.&lt;/p&gt; &lt;p&gt;Clicking on one of the traces will bring you to the trace timeline screen in Figure 12.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/12-jaeger-randomfighters-tracetimeline_1.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/12-jaeger-randomfighters-tracetimeline_1.png?itok=cKo88E2I" width="1397" height="647" alt="The trace timeline for an /api/fights/randomfighters endpoint call is shown." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 12: The trace timeline for an /api/fights/randomfighters endpoint call is shown. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;The trace timeline shows the hierarchy of requests, starting with the initial incoming request into the &lt;code&gt;rest-fights&lt;/code&gt; application. The next few spans in &lt;code&gt;rest-fights&lt;/code&gt; are operations within the &lt;code&gt;rest-fights&lt;/code&gt; application. You can click on each span to get more information about the span, including any incoming method arguments or environment information at the time of the span.&lt;/p&gt; &lt;p&gt;After that, the display shows outgoing HTTP calls from the &lt;code&gt;rest-fights&lt;/code&gt; application to the &lt;code&gt;rest-heroes&lt;/code&gt; and &lt;code&gt;rest-villains&lt;/code&gt; applications called in parallel. The &lt;code&gt;rest-heroes&lt;/code&gt; and &lt;code&gt;rest-villains&lt;/code&gt; timelines even trace down to the database. For example, you can display the executed database query by clicking the second &lt;strong&gt;rest-heroes SELECT Hero&lt;/strong&gt; or &lt;strong&gt;rest-villains SELECT villains_database.Villain&lt;/strong&gt; span and expanding the tags (as shown in Figure 13).&lt;/p&gt; &lt;figure class="align-center" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/13-jaeger-randomfighters-traceherodb.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/13-jaeger-randomfighters-traceherodb.png?itok=JXex6cBB" width="1304" height="995" alt="The database query trace from the rest-heroes application is shown." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 13: The database query trace from the rest-heroes application is shown. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;Each application in the system manages its own sets of traces and spans. The &lt;code&gt;rest-fights&lt;/code&gt; application sends trace context information on the HTTP request so that the &lt;code&gt;rest-heroes&lt;/code&gt; and &lt;code&gt;rest-villains&lt;/code&gt; applications can read it. This way, the complete trace information can be accurately correlated when the &lt;code&gt;rest-fights&lt;/code&gt;, &lt;code&gt;rest-heroes&lt;/code&gt;, and &lt;code&gt;rest-villains&lt;/code&gt; applications export telemetry data to the OpenTelemetry Collector. The Collector then correlates and aggregates all the trace and span information and sends everything to Jaeger.&lt;/p&gt; &lt;p&gt;The &lt;a href="https://quarkus.io/guides/opentelemetry"&gt;Quarkus OpenTelemetry extension&lt;/a&gt; (integrated into all the applications in the system) handles the heavy lifting to make it work.&lt;/p&gt; &lt;h3&gt;Analyzing fights&lt;/h3&gt; &lt;p&gt;Next, let's analyze the traces when performing a fight:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;When you click the &lt;strong&gt;Fight&lt;/strong&gt; button in the Superheroes UI, the browser makes an HTTP request to the &lt;code&gt;/api/fights&lt;/code&gt; endpoint within the &lt;code&gt;rest-fights&lt;/code&gt; application. These services and operations should already be available in the Jaeger UI.&lt;/li&gt; &lt;li&gt;Return to the main Jaeger UI by clicking &lt;strong&gt;JAEGER UI&lt;/strong&gt; in the header at the top of the page.&lt;/li&gt; &lt;li&gt;Once you're back in the main Jaeger UI, select &lt;code&gt;rest-fights&lt;/code&gt; for the &lt;strong&gt;Service&lt;/strong&gt; and &lt;code&gt;/api/fights&lt;/code&gt; for the &lt;strong&gt;Operation (&lt;/strong&gt;see Figure 14).&lt;/li&gt; &lt;li&gt;Then click &lt;strong&gt;Find Traces&lt;/strong&gt;.&lt;/li&gt; &lt;/ol&gt; &lt;figure class="align-center" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/14-jaeger-performfight.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/14-jaeger-performfight.png?itok=Y7afzoSV" width="309" height="712" alt="Fill out the Search boxes as indicated in the text for the /api/fights endpoint." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 14: Fill out the Search boxes as indicated in the text for the /api/fights endpoint. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;As before, a list of traces should appear on the right-hand side of the Jaeger UI as shown in Figure 15.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/15-jaeger-performfight-results.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/15-jaeger-performfight-results.png?itok=FspmSJrF" width="968" height="538" alt="Traces for the /api/fights endpoint are shown." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 15: Traces for the /api/fights endpoint are shown. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;The display shows that each trace contains 8 total spans: 4 spans in the &lt;code&gt;rest-fights&lt;/code&gt; application and 4 spans in the &lt;code&gt;event-statistics&lt;/code&gt; application. Each trace provides the total round-trip time of the request into the &lt;code&gt;/api/fights&lt;/code&gt; endpoint within the &lt;code&gt;rest-fights&lt;/code&gt; application and the total time spent within each unit of work.&lt;/p&gt; &lt;p&gt;Clicking on one of the traces takes you to the trace timeline screen displayed in Figure 16.&lt;/p&gt; &lt;figure class="align-center" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/16-jaeger-performFight-tracetimeline.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/16-jaeger-performFight-tracetimeline.png?itok=HzsG0OQb" width="1300" height="428" alt="A click on each trace shows its timeline." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 16: A click on each trace shows its timeline. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;This trace timeline shows the hierarchy of requests, starting with the initial incoming request into the &lt;code&gt;rest-fights&lt;/code&gt; application. The next few spans in &lt;code&gt;rest-fights&lt;/code&gt; are operations within the &lt;code&gt;rest-fights&lt;/code&gt; application. You can click on each span to get more information about the span, including any incoming method arguments or environment information at the time of the span.&lt;/p&gt; &lt;p&gt;After that, the display shows the &lt;code&gt;rest-fights fights send&lt;/code&gt; span and the &lt;code&gt;event-statistics fights receive&lt;/code&gt; child span. These spans are where the &lt;code&gt;rest-fights&lt;/code&gt; application places a message on an &lt;a href="https://kafka.apache.org"&gt;Apache Kafka&lt;/a&gt; topic, and where the the &lt;code&gt;events-statistics&lt;/code&gt; application consumes the message.&lt;/p&gt; &lt;p&gt;Trace context information is sent along with the message on the Kafka topic from the &lt;code&gt;rest-fights&lt;/code&gt; application and subsequently read by the &lt;code&gt;event-statistics&lt;/code&gt; application when it consumes the message. This way, OpenTelemetry accurately correlates the trace context information when the &lt;code&gt;rest-fights&lt;/code&gt; and &lt;code&gt;event-statistics&lt;/code&gt; applications export telemetry data to the OpenTelemetry Collector. The Collector then correlates and aggregates all the trace and span information and sends everything to Jaeger.&lt;/p&gt; &lt;p&gt;Similar to the previous section, if you click on a span and expand the tags, you can see additional information about each span.&lt;/p&gt; &lt;p&gt;Again, the &lt;a href="https://quarkus.io/guides/opentelemetry"&gt;Quarkus OpenTelemetry extension&lt;/a&gt; (integrated into all the applications in the system) handles the heavy lifting to make it work.&lt;/p&gt; &lt;h2&gt;Quarkus and OpenTelemetry take you deep inside microservices&lt;/h2&gt; &lt;p&gt;Applications today are becoming more and more complex. Typically, multiple applications work together in a distributed fashion to form a usable system. What happens when things don't quite work? What if the system slows down? How do you perform root cause analysis across distributed applications to determine what's going on?&lt;/p&gt; &lt;p&gt;Observability is paramount in these types of systems. It is an invaluable ability to look at distributed trace information to correlate traces and spans, log data, and metrics. This article demonstrated valuable telemetry data and tools to collect it.&lt;/p&gt; &lt;p&gt;Want to learn more about the Quarkus Superheroes? Check out these awesome resources:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://quarkus.io/blog/quarkus-superheroes-to-the-rescue"&gt;Quarkus Superheroes to the Rescue!&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/quarkusio/quarkus-super-heroes"&gt;Quarkus Superheroes GitHub repository&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/03/23/quarkus-superheroes-managed-services-save-day"&gt;Quarkus Superheroes: Managed services save the day&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Want to know more about observability and OpenTelemetry? Check out these great articles:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/04/12/observability-2022-why-it-matters-and-how-opentelemetry-can-help"&gt;Observability in 2022: Why it matters and how OpenTelemetry can help&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/21/distributed-tracing-opentelemetry-knative-and-quarkus"&gt;Distributed tracing with OpenTelemetry, Knative, and Quarkus&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://quarkus.io/guides/opentelemetry"&gt;Quarkus OpenTelemetry guide&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Finally, if you're new to Quarkus, take a look at some of these resources:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/products/quarkus/overview"&gt;Red Hat build of Quarkus: Kubernetes-native Java&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://quarkus.io/get-started"&gt;Getting started with Quarkus&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://quarkus.io/guides"&gt;Quarkus guides&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/08/08/opentelemetry-quarkus-superheroes-demo-observability" title="OpenTelemetry: A Quarkus Superheroes demo of observability"&gt;OpenTelemetry: A Quarkus Superheroes demo of observability&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Eric Deandrea</dc:creator><dc:date>2022-08-08T07:00:00Z</dc:date></entry><entry><title type="html">Quarkus 2.11.2.Final released - CVE-2022-2466 is still ongoing</title><link rel="alternate" href="https://quarkus.io/blog/quarkus-2-11-2-final-released/" /><author><name>Guillaume Smet</name></author><id>https://quarkus.io/blog/quarkus-2-11-2-final-released/</id><updated>2022-08-08T00:00:00Z</updated><content type="html">We thought we got to the bottom of CVE-2022-2466, a security issue we have with GraphQL services since 2.10 was released, but this one keeps on giving. This issue is only of importance to you if you are exposing GraphQL services using the quarkus-smallrye-graphql extension. Consuming GraphQL services is fine....</content><dc:creator>Guillaume Smet</dc:creator></entry></feed>
